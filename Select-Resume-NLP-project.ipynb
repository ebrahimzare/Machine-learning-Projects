{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfextract(file):\n",
    "    fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "    countpage = fileReader.getNumPages()\n",
    "    count = 0\n",
    "    text = []\n",
    "    while count < countpage:    \n",
    "        pageObj = fileReader.getPage(count)\n",
    "        count +=1\n",
    "        t = pageObj.extractText()\n",
    "        print (t)\n",
    "        text.append(t)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack\n",
      " Zemin\n",
      " 1949 Independence Avenue\n",
      " Montreal, Quebec, H4\n",
      "W-2T2\n",
      " Tel: (514) 848\n",
      "-7345 diversity@concordia.ca\n",
      "    OBJECTIVE\n",
      "  Seeking a challenging and de\n",
      "manding su\n",
      "mmer internship position in Infor\n",
      "mation Syste\n",
      "ms  EDUCATION\n",
      "  Bachelor of Computer Science, Information Systems                                   \n",
      "      Expected DATE\n",
      " Concordia University\n",
      ", Montreal, Quebec\n",
      "  Diploma of Computer Technology\n",
      "                                                                                        DATE\n",
      " China University of Technolog\n",
      "y, Tianjin, China\n",
      "  COMPUTER SKILLS\n",
      "  Programming Languages: \n",
      "C, C++, Ht\n",
      "ml, Java, Visual Basic 4.0, COBOL, Perl, XML, CGI\n",
      " Operating Syste\n",
      "ms:           \n",
      " UNIX, DOS, \n",
      "Windows 95/98/XP, Mac OS\n",
      " Soft\n",
      "ware Packages:           \n",
      " MS Office, Visio, Photoshop, Peoplesoft, Siebel, SAP\n",
      " Databases:                           \n",
      "Access, SQL, Oracle, DB2\n",
      "  LANGUAGES\n",
      "  English and French\n",
      "  ACADEMIC PROJECTS\n",
      "  Student \n",
      "Information System\n",
      " Ł Designed and i\n",
      "mple\n",
      "mented an infor\n",
      "mation system\n",
      " for \n",
      "managing certain aspects of \n",
      "registration, course delivery and student records\n",
      " Ł   Devised an Entity\n",
      "-Relationship diagram\n",
      " for databases involved\n",
      " Ł Designed a \n",
      "multi\n",
      "-table relational \n",
      "database using Access and created run\n",
      "-time query \n",
      "state\n",
      "ments using SQL to access data\n",
      " Ł   Constructed a graphic user interface program\n",
      " using Visual Basic 5.0\n",
      " Ł   Coordinated team\n",
      " of five people\n",
      " Ł  Technologies: \n",
      "Windows 2000, Visual Basic 5.0, SQL, Access\n",
      "  Object Oriented Card Game\n",
      " Ł   Designed \n",
      "multi\n",
      "-player card ga\n",
      "me using OOP \n",
      "features\n",
      " Ł   Imple\n",
      "mented classes and GUI using Visual C++\n",
      " Ł   Created a user \n",
      "manual and help file\n",
      " Ł  Technologies: \n",
      "UNIX, Visual C++, Oracle, Java, Swing\n",
      "\n",
      "  Web Page Development\n",
      " Ł   Developed a web page to publish various j\n",
      "-maps in MS Excel\n",
      " Ł   Worked as part of a team\n",
      " of ten individuals in \n",
      "Windows NT 4.0 environ\n",
      "ment\n",
      " Ł   Conducted project status \n",
      "meetings to address difficulties and integration issues\n",
      " Ł   Explored j\n",
      "-maps \n",
      "method \n",
      "for process and product docu\n",
      "mentation\n",
      " Jack\n",
      " Zemin\n",
      " 2/2\n",
      "Ł   Designed and i\n",
      "mple\n",
      "mented several Visual Basic Macros in Excel to construct j\n",
      "-maps\n",
      " Ł   Technologies: \n",
      "Windows NT 4.0, Visual Basic, Excel, Access\n",
      "  CAREER RELATED EXPERIENCE\n",
      "  Programmer Analyst                                                                                               \n",
      "    DATE\n",
      " Merck Frosst Canada Inc.\n",
      ", Kirkland, Quebec\n",
      "  Ł   Designed and progra\n",
      "mmed utilities that supported all aspects of product distribution\n",
      " Ł   Produced detail specifications, defined and executed test plans and coded \n",
      "modules\n",
      " Ł   Collaborated with \n",
      "members of other depart\n",
      "ments to ensure syste\n",
      "m-wide solutions\n",
      " Ł   Provided users with extensive technical support\n",
      "  Service Technician                 \n",
      "                                                                                      DATE\n",
      " Bytes Innovations\n",
      ", Beijing, China\n",
      "  Ł   Installed, i\n",
      "mple\n",
      "mented and integrated network applications for PCs\n",
      " Ł   Provided on\n",
      "-site and telephone support for \n",
      "major proble\n",
      "ms Ł   Trained service engineers and sales personnel\n",
      " Ł   Imple\n",
      "mented a preventative \n",
      "maintenance program\n",
      "  ADDITIONAL EXPERIENCE\n",
      "  Customer Service Representative                                                                            \n",
      "     DATE\n",
      " Chapters\n",
      ", Montreal, Quebec\n",
      "  Ł   Provide custo\n",
      "mers with extensive infor\n",
      "mation based on their needs\n",
      " Ł   Deal with difficult situations in a calm\n",
      " and diplo\n",
      "matic \n",
      "manner\n",
      " Ł   Take initiative to help wherever needed\n",
      "  EXTRA\n",
      "-CURRICULAR ACTIVITIES\n",
      "  External Liason            \n",
      "                                                                                                 \n",
      "     DATE\n",
      " International Students Association \n",
      "Œ Concordia\n",
      ", Montreal, Quebec\n",
      "  Ł   Helped organize a cultural exposition at the university\n",
      " Ł   Recruited new \n",
      "members and participated in telephone fund\n",
      "-raising ca\n",
      "mpaign\n",
      " Ł   Infor\n",
      "med \n",
      "members of upco\n",
      "ming events and \n",
      "meetings\n",
      "  INTERESTS\n",
      "  Chess, hiking, basketball, canoeing, reading co\n",
      "mputer journals and detective novels\n",
      "  References Available Upon Request\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Function to read resumes from the folder one by one\n",
    "mypath=r'Candidate Resume' #enter your path here where you saved the resumes\n",
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "for file in onlyfiles:\n",
    "    text = pdfextract( file) \n",
    "    text = str(text)\n",
    "    text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>R Language</th>\n",
       "      <th>Python Language</th>\n",
       "      <th>NLP</th>\n",
       "      <th>Data Engineering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statistical models</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>neural network</td>\n",
       "      <td>r</td>\n",
       "      <td>python</td>\n",
       "      <td>nlp</td>\n",
       "      <td>aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statistical modeling logistic regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keras</td>\n",
       "      <td>geplot</td>\n",
       "      <td>Flask</td>\n",
       "      <td>natural language processing</td>\n",
       "      <td>ec2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probability</td>\n",
       "      <td>k means</td>\n",
       "      <td>theano</td>\n",
       "      <td>shiny</td>\n",
       "      <td>django</td>\n",
       "      <td>topic modeling</td>\n",
       "      <td>amazon redshift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal distribution random forest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>face detection</td>\n",
       "      <td>cran</td>\n",
       "      <td>pandas</td>\n",
       "      <td>Ida</td>\n",
       "      <td>s3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polsson distribution</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>neural networks</td>\n",
       "      <td>dplyr</td>\n",
       "      <td>Numpy</td>\n",
       "      <td>named entity recognition</td>\n",
       "      <td>docker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>survival models</td>\n",
       "      <td>svm</td>\n",
       "      <td>convlutional neural network(cnn)</td>\n",
       "      <td>tidyr</td>\n",
       "      <td>scikitlearn</td>\n",
       "      <td>pos tagging</td>\n",
       "      <td>kubernetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hypothesis testing</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>recurrent neural network</td>\n",
       "      <td>lubridate</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>factor analysis</td>\n",
       "      <td>decission trees</td>\n",
       "      <td>yolo</td>\n",
       "      <td>knitr</td>\n",
       "      <td>scipy</td>\n",
       "      <td>lst</td>\n",
       "      <td>google big query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>forecasting</td>\n",
       "      <td>svd</td>\n",
       "      <td>gpu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bokeh</td>\n",
       "      <td>spacy</td>\n",
       "      <td>aws lambda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>marcov chain</td>\n",
       "      <td>ensemble models</td>\n",
       "      <td>cuda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>statsmodel</td>\n",
       "      <td>gensim</td>\n",
       "      <td>aws emr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>monte carlo</td>\n",
       "      <td>boltzman machine</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nltk</td>\n",
       "      <td>hive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lstm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nmf</td>\n",
       "      <td>hadoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>opencv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cbow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bag of words</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>skip gram</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Statistics   Machine Learning  \\\n",
       "0                          statistical models  linear regression   \n",
       "1   statistical modeling logistic regression                 NaN   \n",
       "2                                probability             k means   \n",
       "3           normal distribution random forest                NaN   \n",
       "4                        polsson distribution            xgboost   \n",
       "5                             survival models                svm   \n",
       "6                          hypothesis testing        naive bayes   \n",
       "7                             factor analysis    decission trees   \n",
       "8                                forecasting                 svd   \n",
       "9                                marcov chain    ensemble models   \n",
       "10                                monte carlo   boltzman machine   \n",
       "11                                        NaN                NaN   \n",
       "12                                        NaN                NaN   \n",
       "13                                        NaN                NaN   \n",
       "14                                        NaN                NaN   \n",
       "15                                        NaN                NaN   \n",
       "16                                        NaN                NaN   \n",
       "17                                        NaN                NaN   \n",
       "18                                        NaN                NaN   \n",
       "\n",
       "                       Deep Learning R Language Python Language  \\\n",
       "0                     neural network          r          python   \n",
       "1                             keras     geplot           Flask    \n",
       "2                            theano      shiny          django    \n",
       "3                    face detection       cran          pandas    \n",
       "4                    neural networks      dplyr           Numpy   \n",
       "5   convlutional neural network(cnn)      tidyr     scikitlearn   \n",
       "6           recurrent neural network  lubridate         sklearn   \n",
       "7                               yolo      knitr           scipy   \n",
       "8                                gpu        NaN           bokeh   \n",
       "9                               cuda        NaN      statsmodel   \n",
       "10                        tensorflow        NaN             NaN   \n",
       "11                              lstm        NaN             NaN   \n",
       "12                               gan        NaN             NaN   \n",
       "13                            opencv        NaN             NaN   \n",
       "14                               NaN        NaN             NaN   \n",
       "15                               NaN        NaN             NaN   \n",
       "16                               NaN        NaN             NaN   \n",
       "17                               NaN        NaN             NaN   \n",
       "18                               NaN        NaN             NaN   \n",
       "\n",
       "                              NLP  Data Engineering  \n",
       "0                            nlp              aws    \n",
       "1   natural language processing                ec2   \n",
       "2                 topic modeling   amazon redshift   \n",
       "3                            Ida                 s3  \n",
       "4        named entity recognition            docker  \n",
       "5                     pos tagging        kubernetes  \n",
       "6                        word2vec             scala  \n",
       "7                             lst  google big query  \n",
       "8                           spacy        aws lambda  \n",
       "9                          gensim           aws emr  \n",
       "10                           nltk              hive  \n",
       "11                            nmf            hadoop  \n",
       "12                        doc2vec               sql  \n",
       "13                           cbow               NaN  \n",
       "14                   bag of words               NaN  \n",
       "15                      skip gram               NaN  \n",
       "16                           bert               NaN  \n",
       "17                      sentiment               NaN  \n",
       "18                        chatbot               NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_dict = pd.read_csv(r'template_new.csv')\n",
    "keyword_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that does phrase matching and builds a candidate profile\n",
    "def create_profile(file):\n",
    "    text = pdfextract(file) \n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    #below is the csv where we have all the keywords, you can customize your own\n",
    "    keyword_dict = pd.read_csv(r'template_new.csv')\n",
    "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
    "\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Stats', None, *stats_words)\n",
    "    matcher.add('NLP', None, *NLP_words)\n",
    "    matcher.add('ML', None, *ML_words)\n",
    "    matcher.add('DL', None, *DL_words)\n",
    "    matcher.add('R', None, *R_words)\n",
    "    matcher.add('Python', None, *python_words)\n",
    "    matcher.add('DE', None, *Data_Engineering_words)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []  \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "        span = doc[start : end]  # get the matched slice of the doc\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    \n",
    "    ## convertimg string of keywords to dataframe\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    \n",
    "    base = os.path.basename(file)\n",
    "    filename = os.path.splitext(base)[0]\n",
    "       \n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "\n",
    "    return(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack\n",
      " Zemin\n",
      " 1949 Independence Avenue\n",
      " Montreal, Quebec, H4\n",
      "W-2T2\n",
      " Tel: (514) 848\n",
      "-7345 diversity@concordia.ca\n",
      "    OBJECTIVE\n",
      "  Seeking a challenging and de\n",
      "manding su\n",
      "mmer internship position in Infor\n",
      "mation Syste\n",
      "ms  EDUCATION\n",
      "  Bachelor of Computer Science, Information Systems                                   \n",
      "      Expected DATE\n",
      " Concordia University\n",
      ", Montreal, Quebec\n",
      "  Diploma of Computer Technology\n",
      "                                                                                        DATE\n",
      " China University of Technolog\n",
      "y, Tianjin, China\n",
      "  COMPUTER SKILLS\n",
      "  Programming Languages: \n",
      "C, C++, Ht\n",
      "ml, Java, Visual Basic 4.0, COBOL, Perl, XML, CGI\n",
      " Operating Syste\n",
      "ms:           \n",
      " UNIX, DOS, \n",
      "Windows 95/98/XP, Mac OS\n",
      " Soft\n",
      "ware Packages:           \n",
      " MS Office, Visio, Photoshop, Peoplesoft, Siebel, SAP\n",
      " Databases:                           \n",
      "Access, SQL, Oracle, DB2\n",
      "  LANGUAGES\n",
      "  English and French\n",
      "  ACADEMIC PROJECTS\n",
      "  Student \n",
      "Information System\n",
      " Ł Designed and i\n",
      "mple\n",
      "mented an infor\n",
      "mation system\n",
      " for \n",
      "managing certain aspects of \n",
      "registration, course delivery and student records\n",
      " Ł   Devised an Entity\n",
      "-Relationship diagram\n",
      " for databases involved\n",
      " Ł Designed a \n",
      "multi\n",
      "-table relational \n",
      "database using Access and created run\n",
      "-time query \n",
      "state\n",
      "ments using SQL to access data\n",
      " Ł   Constructed a graphic user interface program\n",
      " using Visual Basic 5.0\n",
      " Ł   Coordinated team\n",
      " of five people\n",
      " Ł  Technologies: \n",
      "Windows 2000, Visual Basic 5.0, SQL, Access\n",
      "  Object Oriented Card Game\n",
      " Ł   Designed \n",
      "multi\n",
      "-player card ga\n",
      "me using OOP \n",
      "features\n",
      " Ł   Imple\n",
      "mented classes and GUI using Visual C++\n",
      " Ł   Created a user \n",
      "manual and help file\n",
      " Ł  Technologies: \n",
      "UNIX, Visual C++, Oracle, Java, Swing\n",
      "\n",
      "  Web Page Development\n",
      " Ł   Developed a web page to publish various j\n",
      "-maps in MS Excel\n",
      " Ł   Worked as part of a team\n",
      " of ten individuals in \n",
      "Windows NT 4.0 environ\n",
      "ment\n",
      " Ł   Conducted project status \n",
      "meetings to address difficulties and integration issues\n",
      " Ł   Explored j\n",
      "-maps \n",
      "method \n",
      "for process and product docu\n",
      "mentation\n",
      " Jack\n",
      " Zemin\n",
      " 2/2\n",
      "Ł   Designed and i\n",
      "mple\n",
      "mented several Visual Basic Macros in Excel to construct j\n",
      "-maps\n",
      " Ł   Technologies: \n",
      "Windows NT 4.0, Visual Basic, Excel, Access\n",
      "  CAREER RELATED EXPERIENCE\n",
      "  Programmer Analyst                                                                                               \n",
      "    DATE\n",
      " Merck Frosst Canada Inc.\n",
      ", Kirkland, Quebec\n",
      "  Ł   Designed and progra\n",
      "mmed utilities that supported all aspects of product distribution\n",
      " Ł   Produced detail specifications, defined and executed test plans and coded \n",
      "modules\n",
      " Ł   Collaborated with \n",
      "members of other depart\n",
      "ments to ensure syste\n",
      "m-wide solutions\n",
      " Ł   Provided users with extensive technical support\n",
      "  Service Technician                 \n",
      "                                                                                      DATE\n",
      " Bytes Innovations\n",
      ", Beijing, China\n",
      "  Ł   Installed, i\n",
      "mple\n",
      "mented and integrated network applications for PCs\n",
      " Ł   Provided on\n",
      "-site and telephone support for \n",
      "major proble\n",
      "ms Ł   Trained service engineers and sales personnel\n",
      " Ł   Imple\n",
      "mented a preventative \n",
      "maintenance program\n",
      "  ADDITIONAL EXPERIENCE\n",
      "  Customer Service Representative                                                                            \n",
      "     DATE\n",
      " Chapters\n",
      ", Montreal, Quebec\n",
      "  Ł   Provide custo\n",
      "mers with extensive infor\n",
      "mation based on their needs\n",
      " Ł   Deal with difficult situations in a calm\n",
      " and diplo\n",
      "matic \n",
      "manner\n",
      " Ł   Take initiative to help wherever needed\n",
      "  EXTRA\n",
      "-CURRICULAR ACTIVITIES\n",
      "  External Liason            \n",
      "                                                                                                 \n",
      "     DATE\n",
      " International Students Association \n",
      "Œ Concordia\n",
      ", Montreal, Quebec\n",
      "  Ł   Helped organize a cultural exposition at the university\n",
      " Ł   Recruited new \n",
      "members and participated in telephone fund\n",
      "-raising ca\n",
      "mpaign\n",
      " Ł   Infor\n",
      "med \n",
      "members of upco\n",
      "ming events and \n",
      "meetings\n",
      "  INTERESTS\n",
      "  Chess, hiking, basketball, canoeing, reading co\n",
      "mputer journals and detective novels\n",
      "  References Available Upon Request\n",
      " \n",
      "  Candidate Name Subject Keyword Count\n",
      "0         resume      DE    sql      3\n",
      "  Candidate Name Subject Keyword Count\n",
      "0         resume      DE    sql      3\n"
     ]
    }
   ],
   "source": [
    "#code to execute/call the above functions\n",
    " \n",
    "final_database=pd.DataFrame()\n",
    "i = 0 \n",
    "while i < len(onlyfiles):\n",
    "    file = onlyfiles[i]\n",
    "    dat = create_profile(file)\n",
    "    print(dat)\n",
    "    final_database = final_database.append(dat)\n",
    "    i +=1\n",
    "    print(final_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    sql \n",
      "Name: Keyword, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_database['Keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code to count words under each category and visulaize it through Matplotlib\n",
    " \n",
    "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "final_database2.reset_index(inplace = True)\n",
    "final_database2.fillna(0,inplace=True)\n",
    "new_data = final_database2.iloc[:,1:]\n",
    "new_data.index = final_database2['Candidate Name']\n",
    "#execute the below line if you want to see the candidate profile in a csv format\n",
    "#sample2=new_data.to_csv('sample.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(25,7), stacked=True)\n",
    "labels = []\n",
    "for j in new_data.columns:\n",
    "    for i in new_data.index:\n",
    "        label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "        labels.append(label)\n",
    "patches = ax.patches\n",
    "for label, rect in zip(labels, patches):\n",
    "    width = rect.get_width()\n",
    "    if width > 0:\n",
    "        x = rect.get_x()\n",
    "        y = rect.get_y()\n",
    "        height = rect.get_height()\n",
    "        ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
